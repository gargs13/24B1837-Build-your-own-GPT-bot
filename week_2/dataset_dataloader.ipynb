{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf073e73-732c-44ce-aac7-f372b57fc31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mini-batch gradient descent\n",
    "\n",
    "batch_size=32\n",
    "epochs=25\n",
    "n_samples=len(X_train_tensor)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for start_idx in range(0, n_samples, batch_size):\n",
    "        end_idx=start_idx+batch_size\n",
    "        X_batch=X_train_tensor[start_idx:end_idx]\n",
    "        y_batch=y_train_tensor[start_idx:end_idx]\n",
    "\n",
    "        y_pred=model(X_batch)\n",
    "        loss=loss_function(y_pred, y_batch,view)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a7711a2-b981-4d33-bd81-977dae1509a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2e27b84-3ec5-4625-9e08-68e186ea7c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create a synthetic classification dataset using sklearn\n",
    "X, y = make_classification(\n",
    "    n_samples=10,       # Number of samples\n",
    "    n_features=2,       # Number of features\n",
    "    n_informative=2,    # Number of informative features\n",
    "    n_redundant=0,      # Number of redundant features\n",
    "    n_classes=2,        # Number of classes\n",
    "    random_state=42     # For reproducibility\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a475013-fe6a-4035-af55-0f03e6639988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the data to PyTorch tensors\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65726187-bda9-4362-ba64-2451d80c6821",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "\n",
    "  def __init__(self, features, labels):\n",
    "\n",
    "    self.features = features\n",
    "    self.labels = labels\n",
    "\n",
    "  def __len__(self):\n",
    "\n",
    "    return self.features.shape[0]\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "\n",
    "    return self.features[index], self.labels[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49017d55-f300-4a77-8515-3225e1317ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDataset(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "570d6d5b-d817-42a6-9e5f-ee917411a56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5518449-b1bc-41c8-85cc-61c1b2549823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.0683, -0.9701],\n",
      "        [-1.1402, -0.8388]])\n",
      "tensor([1, 0])\n",
      "--------------------------------------------------\n",
      "tensor([[-2.8954,  1.9769],\n",
      "        [-0.7206, -0.9606]])\n",
      "tensor([0, 0])\n",
      "--------------------------------------------------\n",
      "tensor([[-1.9629, -0.9923],\n",
      "        [-0.9382, -0.5430]])\n",
      "tensor([0, 1])\n",
      "--------------------------------------------------\n",
      "tensor([[ 1.7273, -1.1858],\n",
      "        [ 1.7774,  1.5116]])\n",
      "tensor([1, 1])\n",
      "--------------------------------------------------\n",
      "tensor([[ 1.8997,  0.8344],\n",
      "        [-0.5872, -1.9717]])\n",
      "tensor([1, 0])\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for batch_features, batch_labels in dataloader:\n",
    "\n",
    "  print(batch_features)\n",
    "  print(batch_labels)\n",
    "  print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903c442d-bd70-40f2-b8b8-e68871b43af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9de9717-794e-404e-a452-8b985cb47707",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "\n",
    "  def __init__(self, features, labels):\n",
    "\n",
    "    self.features = features\n",
    "    self.labels = labels\n",
    "\n",
    "  def __len__(self):\n",
    "\n",
    "    return len(self.features)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "\n",
    "    return self.features[idx], self.labels[idx]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0ee43e2-9414-4b50-8e15-a2e3acf55f6a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_tensor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m CustomDataset(X_train_tensor, y_train_tensor)\n\u001b[0;32m      2\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m CustomDataset(X_test_tensor, y_test_tensor)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train_tensor' is not defined"
     ]
    }
   ],
   "source": [
    "train_dataset = CustomDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = CustomDataset(X_test_tensor, y_test_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03409ab7-35fe-4c51-9f12-2de8e289afef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class MySimpleNN(nn.Module):\n",
    "\n",
    "  def __init__(self, num_features):\n",
    "\n",
    "    super().__init__()\n",
    "    self.linear = nn.Linear(num_features, 1)\n",
    "    self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "  def forward(self, features):\n",
    "\n",
    "    out = self.linear(features)\n",
    "    out = self.sigmoid(out)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5b1189-9c75-4665-aedb-43fb2a7a1e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "epochs = 25\n",
    "# create model\n",
    "model = MySimpleNN(X_train_tensor.shape[1])\n",
    "\n",
    "# define optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# define loss function\n",
    "loss_function = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f597396-4880-4ad8-a7e8-7af1edd06a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define loop\n",
    "for epoch in range(epochs):\n",
    "\n",
    "  for batch_features, batch_labels in train_loader:\n",
    "\n",
    "    # forward pass\n",
    "    y_pred = model(batch_features)\n",
    "\n",
    "    # loss calculate\n",
    "    loss = loss_function(y_pred, batch_labels.view(-1,1))\n",
    "\n",
    "    # clear gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    # parameters update\n",
    "    optimizer.step()\n",
    "\n",
    "  # print loss in each epoch\n",
    "  print(f'Epoch: {epoch + 1}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918c611f-7430-4b13-96ca-849051cdeb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model evaluation using test_loader\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "accuracy_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_features, batch_labels in test_loader:\n",
    "        # Forward pass\n",
    "        y_pred = model(batch_features)\n",
    "        y_pred = (y_pred > 0.8).float()  # Convert probabilities to binary predictions\n",
    "\n",
    "        # Calculate accuracy for the current batch\n",
    "        batch_accuracy = (y_pred.view(-1) == batch_labels).float().mean().item()\n",
    "        accuracy_list.append(batch_accuracy)\n",
    "\n",
    "# Calculate overall accuracy\n",
    "overall_accuracy = sum(accuracy_list) / len(accuracy_list)\n",
    "print(f'Accuracy: {overall_accuracy:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
