{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19eae228-7d03-4cfd-900e-c520e69712bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import nltk\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import gensim\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "import gensim.downloader as api\n",
    "import pandas as pd\n",
    "import kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2c9b96-1a84-4122-a779-056e1fa45a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = kagglehub.dataset_download(\"rmisra/news-category-dataset\")\n",
    "df=pd.read_json(path, lines=True)\n",
    "#df=pd.read_json(\"C:\\\\Users\\\\Gargi Joshi\\\\Build-your-own-GPT-bot\\\\dataset\\\\News_Category_Dataset_v3.json\", lines=True)\n",
    "headlines= df['headline']\n",
    "\n",
    "documents=[]\n",
    "for i in range(1000): #entire data is 205927 or smtg nd i was done with the loading tf\n",
    "    documents.append(headlines[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8b862a-00bb-4c89-ba96-d2e7edb9ab58",
   "metadata": {},
   "outputs": [],
   "source": [
    "snowballstemmer=SnowballStemmer('english')\n",
    "all_stopwords=stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a379bca4-75b7-4aa6-8cbe-77963c6af586",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [word_tokenize(doc.lower()) for doc in documents]\n",
    "\n",
    "for i in range(len(words)):\n",
    "    words[i]=[snowballstemmer.stem(word) for word in words[i] if word not in all_stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee709d78-ed0a-4701-8929-3c6974b1c69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Word2Vec(words, min_count=1)\n",
    "vocabulary = list(model.wv.index_to_key)\n",
    "avg_vector=[]\n",
    "for i in range(len(words)-1):\n",
    "    sum_vectors=0\n",
    "    for j in range(len(words[i])):\n",
    "        sum_vectors=sum_vectors+model.wv[words[i][j]]\n",
    "    avg_vector.append(sum_vectors/len(words[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e318816-f0d9-40ea-b35e-779104fb7e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sent=str(input(\"enter sentence:\"))\n",
    "input_words=word_tokenize(input_sent.lower())\n",
    "for i in range(len(input_words)):\n",
    "    input_words[i]=snowballstemmer.stem(input_words[i])\n",
    "input_vector=[model.wv[word] for word in input_words if word in vocabulary]\n",
    "sum_input=0\n",
    "for i in range(len(input_vector)):\n",
    "    sum_input=sum_input+input_vector[i]\n",
    "avg_input_vector=sum_input/len(input_vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc9094d-0069-4453-aab6-dd779ce86eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "cosine_similarity= [(np.dot(avg_input_vector, avg_i)/(np.linalg.norm(avg_input_vector)* np.linalg.norm(avg_i))) for avg_i in avg_vector]\n",
    "distance=[1-cosine for cosine in cosine_similarity]\n",
    "ascending_order=sorted(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e3f19c-1ef2-4604-96b6-1c96b35b46e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "order=[]\n",
    "for i in range(5):\n",
    "    for j in range(len(ascending_order)):\n",
    "        if ascending_order[i]==distance[j]:\n",
    "            order.append(j)\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91724e6-4095-4929-9562-20a4f6680dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5=[documents[order[i]] for i in range(5)]\n",
    "print(top_5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
