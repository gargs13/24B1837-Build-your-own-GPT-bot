{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNgJFuqWf9ImT0A8zCMJwK4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gargs13/24B1837-Build-your-own-GPT-bot/blob/main/sent_analysis_bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "bsTkIOktTGuz"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer as bt\n",
        "from transformers import BertModel as bm\n",
        "from transformers import BertForSequenceClassification as bc\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\n",
        "import torch.nn as nn\n",
        "from collections import Counter\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import numpy as np\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('//content//IMDB Dataset.csv')\n",
        "#df = df.sample(10000, random_state=42).reset_index(drop=True)\n",
        "reviews=[]\n",
        "sentiments=[]\n",
        "for i in range(len(df['review'])):\n",
        "    reviews.append(df[\"review\"][i])\n",
        "\n",
        "sentiments = df['sentiment'].map({'positive': 1, 'negative': 0})"
      ],
      "metadata": {
        "id": "jsuh0h3oUT4d"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiments[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D22wSOadiHQH",
        "outputId": "bf94301e-1ff6-4b4d-bac1-b88d8aa638c4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.int64(1)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ReviewDataset(Dataset):\n",
        "    def __init__(self, data, labels):\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "        self.lengths = [len(word_tokenize(review)) for review in data]\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx], self.labels[idx], self.lengths[idx]\n"
      ],
      "metadata": {
        "id": "txyfkUG6UWGP"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bt=bt.from_pretrained('bert-base-uncased')\n",
        "\n",
        "def format(batch):\n",
        "  texts, labels, lengths = zip(*batch)\n",
        "  tokens = bt(list(texts), padding=True, truncation=True, max_length=128, return_tensors=\"pt\")\n",
        "  labels = torch.tensor(labels, dtype=torch.long)\n",
        "  return tokens, labels"
      ],
      "metadata": {
        "id": "pY0-cKp3lmCd"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = ReviewDataset(reviews, sentiments)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
        "train_dl = DataLoader(train_ds, batch_size=32, shuffle=True, collate_fn=format)\n",
        "val_dl = DataLoader(val_ds, batch_size=32, collate_fn=format)\n"
      ],
      "metadata": {
        "id": "Xjmozo73Uesy"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mPM6i2LSk2Ef"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hKpvGmC4VNTP"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = bc.from_pretrained('bert-base-uncased', num_labels=2).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=3e-5, weight_decay=1e-5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-9SSawCdF8G",
        "outputId": "dcd45514-047a-430d-cc97-aaf216a276ed"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J8fMnwZChVNu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss, correct, total = 0, 0, 0\n",
        "    for tokens, labels in train_dl:\n",
        "        input_ids = tokens['input_ids'].to(device)\n",
        "        attention_mask = tokens['attention_mask'].to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        logits = outputs.logits\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}: Train Loss = {total_loss:.4f}, Accuracy = {correct/total:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ufLhmP3dICK",
        "outputId": "e3e95fb5-707b-4b01-cafe-1a1799617bfc"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss = 399.8131, Accuracy = 0.8557\n",
            "Epoch 2: Train Loss = 227.8634, Accuracy = 0.9293\n",
            "Epoch 3: Train Loss = 114.9483, Accuracy = 0.9676\n",
            "Epoch 4: Train Loss = 60.3040, Accuracy = 0.9839\n",
            "Epoch 5: Train Loss = 44.9911, Accuracy = 0.9879\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "val_correct, val_total = 0, 0\n",
        "with torch.no_grad():\n",
        "    for tokens, labels in val_dl:\n",
        "        input_ids = tokens['input_ids'].to(device)\n",
        "        attention_mask = tokens['attention_mask'].to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        preds = torch.argmax(outputs.logits, dim=1)\n",
        "        val_correct += (preds == labels).sum().item()\n",
        "        val_total += labels.size(0)\n",
        "\n",
        "val_acc = val_correct / val_total\n",
        "print(f\"Validation Accuracy = {val_acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "muXi4fEl8KWI",
        "outputId": "992dfd28-2990-454b-e2d7-b934acb8907d"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy = 0.8655\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sentiment(text, device):\n",
        "    model.eval()\n",
        "    tokens = bt(text, padding=True, truncation=True, return_tensors=\"pt\", max_length=128)\n",
        "    tokens = {k: v.to(device) for k, v in tokens.items()}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(**tokens)\n",
        "        logits = output.logits\n",
        "        probs = torch.softmax(logits, dim=1)\n",
        "        confidence, pred_class = torch.max(probs, dim=1)\n",
        "        label = \"Positive\" if pred_class.item() == 1 else \"Negative\"\n",
        "        print(f\"Prediction: {label} ({confidence.item():.4f})\")\n",
        "\n",
        "\n",
        "string=str(input(\"Enter review:\"))\n",
        "predict_sentiment(string, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0t9F28s8UiQ",
        "outputId": "892c1734-bdcf-4d19-910e-036af12eeadb"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter review:it was a fine movie\n",
            "Prediction: Positive (0.9985)\n"
          ]
        }
      ]
    }
  ]
}